"""Tool registry based on Vanna Tool API."""

from __future__ import annotations

import json
import logging
from datetime import date, datetime
from typing import Any, Dict, List, Optional, Tuple

import pandas as pd

logger = logging.getLogger(__name__)


def _json_serial(obj):
    """JSON serializer for objects not serializable by default."""
    if isinstance(obj, (datetime, date)):
        return obj.isoformat()
    raise TypeError(f"Type {type(obj)} not serializable")


from pydantic import BaseModel, Field
from vanna.core.tool import Tool, ToolContext, ToolResult
from vanna.tools import RunSqlTool
from vanna.tools.file_system import LocalFileSystem
from vanna.core.registry import ToolRegistry

from ai_chat.vanna.sql_runner import FinanceSqlRunner
from ai_chat.vanna.employee_sql_runner import EmployeeSqlRunner
from ai_chat.vanna.vectorstore import similarity_search
from ai_chat.prompts.system import FIELD_DISPLAY_MAPPING, COMPANY_MAPPING
from common.auth.service import Roles


def _get_display_name(field: str) -> str:
    """è·å–å­—æ®µçš„ä¸­æ–‡æ˜¾ç¤ºåã€‚"""
    return FIELD_DISPLAY_MAPPING.get(field, field)


def _get_company_name(company_no: str) -> str:
    """å°†å…¬å¸ç¼–å·è½¬æ¢ä¸ºä¸­æ–‡åç§°ã€‚"""
    return COMPANY_MAPPING.get(company_no, company_no)


class SearchArgs(BaseModel):
    query: str = Field(description="æ£€ç´¢é—®é¢˜æˆ–å…³é”®è¯")
    top_k: int = Field(default=5, ge=1, le=20, description="è¿”å›ç‰‡æ®µæ•°é‡")


class ChartArgs(BaseModel):
    chart_type: str = Field(default="bar", description="å›¾è¡¨ç±»å‹: line(æŠ˜çº¿å›¾), bar(æŸ±çŠ¶å›¾), pie(é¥¼å›¾)")
    title: Optional[str] = Field(default=None, description="å›¾è¡¨æ ‡é¢˜")
    additional_charts: Optional[List[str]] = Field(
        default=None,
        description="ä»…å½“ç”¨æˆ·æ˜ç¡®è¦æ±‚å¤šç§å›¾è¡¨æ—¶ä½¿ç”¨ã€‚é»˜è®¤åªç”Ÿæˆä¸€ä¸ªå›¾è¡¨ã€‚"
    )


class EmployeeChartArgs(BaseModel):
    """å‘˜å·¥å›¾è¡¨ç”Ÿæˆå‚æ•°"""
    chart_type: Optional[str] = Field(default=None, description="å›¾è¡¨ç±»å‹: bar(æŸ±çŠ¶å›¾), pie(é¥¼å›¾)")
    title: Optional[str] = Field(default=None, description="å›¾è¡¨æ ‡é¢˜")


# å‘˜å·¥è¡¨å­—æ®µ -> ä¸­æ–‡æ˜¾ç¤ºåæ˜ å°„
EMPLOYEE_COLUMN_LABELS = {
    "name": "å§“å",
    "company_name": "å…¬å¸",
    "company_no": "å…¬å¸ç¼–å·",
    "department": "éƒ¨é—¨",
    "position": "èŒåŠ¡",
    "gender": "æ€§åˆ«",
    "employee_level": "å‘˜å·¥çº§åˆ«",
    "is_contract": "æ˜¯/å¦åŠ³åŠ¨åˆåŒå·¥",
    "highest_education": "å­¦å†",
    "graduate_school": "æ¯•ä¸šé™¢æ ¡",
    "major": "ä¸“ä¸š",
    "political_status": "æ”¿æ²»é¢è²Œ",
    "professional_title": "èŒç§°",
    "skill_level": "æŠ€èƒ½ç­‰çº§",
    "hire_date": "å…¥èŒæ—¥æœŸ",
    "id_number": "èº«ä»½è¯å·",
    "phone": "ç”µè¯",
}


class EmployeeQueryArgs(BaseModel):
    sql: str = Field(description="æŸ¥è¯¢å‘˜å·¥æ•°æ®çš„ SQL è¯­å¥")


class SearchResult(BaseModel):
    """Structured search result for frontend rendering."""
    article_id: str
    title: str
    source_name: Optional[str] = None
    publish_time: Optional[str] = None
    text: str
    score: float


class SearchArticlesTool(Tool[SearchArgs]):
    """å‘é‡æ£€ç´¢å·¥å…·ï¼Œç›´æ¥æŸ¥ pgvector."""

    @property
    def name(self) -> str:
        return "search_policy_articles"

    @property
    def description(self) -> str:
        return "åŸºäºå‘é‡æ£€ç´¢åŒ»è¯æ”¿ç­–/è¡Œä¸šèµ„è®¯ç‰‡æ®µï¼Œè¿”å›æœ€ç›¸å…³çš„æ®µè½"

    def get_args_schema(self):
        return SearchArgs

    async def execute(self, context: ToolContext, args: SearchArgs) -> ToolResult:
        results = similarity_search(args.query, top_k=args.top_k)

        # Build structured search results for frontend
        search_results: List[Dict[str, Any]] = []
        summary = []
        for item in results:
            meta = item.get("metadata") or {}
            title = meta.get("title") or "[æœªå‘½å]"
            text = item.get("text", "")

            # Structured result
            search_results.append({
                "article_id": meta.get("article_id", ""),
                "title": title,
                "source_name": meta.get("source_name"),
                "publish_time": meta.get("publish_time"),
                "text": text[:500] if text else "",  # Truncate for display
                "score": item.get("score", 0),
            })

            # Summary for top 3
            if len(summary) < 3:
                summary.append(f"- {title}")

        # ç®€åŒ– result_for_llmï¼Œåªè¿”å›ç²¾ç®€æ‘˜è¦ï¼Œä¸æš´éœ² JSON ç»†èŠ‚
        llm_text = (
            "æ£€ç´¢åˆ°ä»¥ä¸‹ç›¸å…³æ”¿ç­–å†…å®¹ï¼Œè¯·ç”¨è‡ªç„¶è¯­è¨€æ€»ç»“å›ç­”ç”¨æˆ·é—®é¢˜ï¼š\n"
            + "\n".join([
                f"- ã€Š{item.get('metadata', {}).get('title', 'æœªçŸ¥')}ã€‹: {(item.get('text', '') or '')[:300]}"
                for item in results[:5]
            ])
            if results else "æœªæ‰¾åˆ°ç›¸å…³å†…å®¹"
        )
        return ToolResult(
            success=True,
            result_for_llm=llm_text,
            metadata={
                "results": results,
                "search_results": search_results,  # Structured for frontend
            },
        )


class FinanceChartTool(Tool[ChartArgs]):
    """åŸºäºæœ€è¿‘çš„è´¢åŠ¡æŸ¥è¯¢ç»“æœç”Ÿæˆå¯è§†åŒ–å›¾è¡¨ã€‚"""

    @property
    def name(self) -> str:
        return "generate_finance_chart"

    @property
    def description(self) -> str:
        return "åŸºäºæœ€è¿‘çš„è´¢åŠ¡æ•°æ®æŸ¥è¯¢ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨ï¼ˆæŸ±çŠ¶å›¾/æŠ˜çº¿å›¾/é¥¼å›¾ï¼‰ï¼Œéœ€å…ˆè°ƒç”¨ query_finance_sql"

    def get_args_schema(self):
        return ChartArgs

    async def execute(self, context: ToolContext, args: ChartArgs) -> ToolResult:
        # ä» context.metadata è·å–ä¸Šä¸€æ¬¡ SQL æŸ¥è¯¢çš„ç»“æœ
        tool_log = context.metadata.get("tool_log", [])
        last_sql = next(
            (t for t in reversed(tool_log) if t.get("tool_name") == "query_finance_sql"),
            None,
        )

        if not last_sql:
            return ToolResult(success=False, error="è¯·å…ˆè°ƒç”¨ query_finance_sql æŸ¥è¯¢è´¢åŠ¡æ•°æ®")

        metadata = last_sql.get("metadata") or {}

        # ä¼˜å…ˆä½¿ç”¨ metadata ä¸­çš„ç»“æ„åŒ–æ•°æ®ï¼ˆVanna RunSqlTool è¿”å›ï¼‰
        results = metadata.get("results")
        columns = metadata.get("columns")

        if results and columns:
            # ä½¿ç”¨ç»“æ„åŒ–æ•°æ®
            chart_data = {"headers": columns, "rows": results}
            logger.info(f"ğŸ” [FinanceChart] Using structured data: columns={columns}, row_count={len(results)}")
        else:
            # å›é€€åˆ°è§£æ CSV æ–‡æœ¬ï¼ˆå…¼å®¹æ—§ç‰ˆæœ¬ï¼‰
            result_text = last_sql.get("result_for_llm", "")
            chart_data = self._parse_sql_result(result_text)
            logger.info(f"ğŸ” [FinanceChart] Parsed CSV data: {chart_data}")

        if not chart_data:
            return ToolResult(success=False, error="æ— æ³•è§£æè´¢åŠ¡æ•°æ®ï¼Œè¯·é‡æ–°æŸ¥è¯¢")

        # å›¾è¡¨ç±»å‹ä¸­æ–‡åæ˜ å°„
        chart_type_names = {"bar": "æŸ±çŠ¶å›¾", "line": "æŠ˜çº¿å›¾", "pie": "é¥¼å›¾"}

        # æ„å»ºå¤šä¸ªå›¾è¡¨
        charts = []
        base_title = args.title or "è´¢åŠ¡æ•°æ®"

        # ä¸»å›¾è¡¨ï¼ˆPlotly æ ¼å¼ï¼‰
        plotly_config = self._build_plotly_config(chart_data, args.chart_type, base_title)
        charts.append({
            "chart_type": args.chart_type,
            "config": plotly_config,
            "title": f"{base_title}{chart_type_names.get(args.chart_type, args.chart_type)}",
        })

        # é¢å¤–å›¾è¡¨
        if args.additional_charts:
            for ct in args.additional_charts[:2]:  # æœ€å¤š2ä¸ªé¢å¤–å›¾è¡¨
                ct = ct.lower().strip()
                if ct in ("bar", "line", "pie") and ct != args.chart_type:
                    extra_config = self._build_plotly_config(chart_data, ct, base_title)
                    charts.append({
                        "chart_type": ct,
                        "config": extra_config,
                        "title": f"{base_title}{chart_type_names.get(ct, ct)}",
                    })

        chart_count = len(charts)
        return ToolResult(
            success=True,
            result_for_llm=f"å·²ç”Ÿæˆ {chart_count} ä¸ªå›¾è¡¨",
            metadata={
                "charts": charts,  # å¤æ•°å½¢å¼ï¼Œæ”¯æŒå¤šå›¾è¡¨
            },
        )

    def _parse_sql_result(self, result_text: str) -> Optional[Dict[str, Any]]:
        """è§£æ SQL æŸ¥è¯¢ç»“æœæ–‡æœ¬ï¼Œæå–æ•°æ®ã€‚"""
        if not result_text:
            return None

        lines = result_text.strip().split("\n")
        if len(lines) < 2:
            return None

        # ç¬¬ä¸€è¡Œæ˜¯åˆ—å
        headers = [h.strip() for h in lines[0].split(",")]
        rows = []
        for line in lines[1:]:
            if not line.strip() or line.startswith("Results saved"):
                continue
            values = [v.strip() for v in line.split(",")]
            if len(values) == len(headers):
                rows.append(dict(zip(headers, values)))

        if not rows:
            return None

        return {"headers": headers, "rows": rows}

    def _build_plotly_config(self, data: Dict[str, Any], chart_type: str, title: str = "") -> Dict[str, Any]:
        """æ ¹æ®æ•°æ®å’Œå›¾è¡¨ç±»å‹æ„å»º Plotly é…ç½®ã€‚

        æ™ºèƒ½æ£€æµ‹æ•°æ®ç»´åº¦ï¼Œæ”¯æŒï¼š
        - å¤šå…¬å¸æ—¶é—´åºåˆ—ï¼šæŒ‰å…¬å¸åˆ†ç»„ï¼Œæ¯å…¬å¸ä¸€æ¡çº¿/æŸ±
        - å¤šå…¬å¸å•æ—¶é—´ç‚¹ï¼šXè½´ä¸ºå…¬å¸ï¼ŒæŸ±çŠ¶å›¾å¯¹æ¯”
        - å¤šæŒ‡æ ‡æ—¶é—´åºåˆ—ï¼šæŒ‰æŒ‡æ ‡åˆ†ç»„
        - å•ç³»åˆ—ï¼šåŸæœ‰é€»è¾‘
        """
        headers = data["headers"]
        rows = data["rows"]
        logger.info(f"ğŸ” [FinanceChart] _build_plotly_config called: chart_type={chart_type}, headers={headers}, row_count={len(rows)}")

        # Plotly é…è‰²æ–¹æ¡ˆï¼ˆæ‰©å±•åˆ°æ”¯æŒæ›´å¤šç³»åˆ—ï¼‰
        colors = [
            "#3b82f6", "#10b981", "#f59e0b", "#ef4444", "#8b5cf6", "#ec4899",
            "#06b6d4", "#84cc16", "#f97316", "#6366f1", "#14b8a6", "#a855f7",
        ]

        # 1. è¯†åˆ«æ•°æ®ç»´åº¦
        has_company = "company_name" in headers
        has_time = "keep_date" in headers
        has_type = "type_name" in headers

        # è¯†åˆ«æ•°å€¼åˆ—
        value_cols = []
        for h in headers:
            h_lower = h.lower()
            if any(k in h_lower for k in ["amount", "rate", "total", "revenue", "profit"]):
                value_cols.append(h)
        if not value_cols and len(headers) > 1:
            # æ’é™¤å·²çŸ¥çš„åˆ†ç±»åˆ—
            exclude = {"company_name", "company_no", "keep_date", "type_name", "type_no"}
            value_cols = [h for h in headers if h not in exclude][:2]

        logger.info(f"ğŸ” [FinanceChart] Identified value_cols: {value_cols}")
        val_col = value_cols[0] if value_cols else headers[-1]

        # 2. é¥¼å›¾ç‰¹æ®Šå¤„ç†
        if chart_type == "pie":
            return self._build_pie_config(rows, headers, val_col, colors, title)

        # 3. ç¡®å®šåˆ†ç»„ç­–ç•¥
        group_col = None
        x_col = None

        if has_company and has_time:
            # åœºæ™¯1ï¼šå¤šå…¬å¸æ—¶é—´åºåˆ— â†’ æŒ‰å…¬å¸åˆ†ç»„ï¼ŒXè½´ä¸ºæ—¶é—´
            group_col = "company_name"
            x_col = "keep_date"
        elif has_type and has_time:
            # åœºæ™¯3ï¼šå¤šæŒ‡æ ‡æ—¶é—´åºåˆ— â†’ æŒ‰æŒ‡æ ‡åˆ†ç»„
            group_col = "type_name"
            x_col = "keep_date"
        elif has_company and not has_time:
            # åœºæ™¯2ï¼šå¤šå…¬å¸å•æ—¶é—´ç‚¹ â†’ Xè½´ä¸ºå…¬å¸
            group_col = None
            x_col = "company_name"
        elif has_time:
            # å•å…¬å¸æ—¶é—´åºåˆ—
            group_col = None
            x_col = "keep_date"
        else:
            # é»˜è®¤ï¼šä½¿ç”¨ç¬¬ä¸€åˆ—ä½œä¸ºXè½´
            x_col = headers[0] if headers else None

        # 4. æ„å»º traces
        logger.info(f"ğŸ” [FinanceChart] Strategy: group_col={group_col}, x_col={x_col}, value_cols={value_cols}")
        if group_col:
            # éªŒè¯åˆ†ç»„åˆ—æ˜¯å¦æœ‰æœ‰æ•ˆå€¼ï¼ˆéNone/ç©ºå­—ç¬¦ä¸²ï¼‰
            valid_groups = [row.get(group_col) for row in rows if row.get(group_col)]
            if valid_groups:
                traces = self._build_grouped_traces(rows, group_col, x_col, val_col, chart_type, colors)
            else:
                # åˆ†ç»„åˆ—å…¨æ˜¯Noneï¼Œé™çº§ä¸ºå•ç³»åˆ—å±•ç¤º
                logger.info(f"ğŸ” [FinanceChart] Group column '{group_col}' has no valid values, falling back to single trace")
                group_col = None
                traces = self._build_single_traces(rows, x_col, value_cols, chart_type, colors)
        else:
            traces = self._build_single_traces(rows, x_col, value_cols, chart_type, colors)
        logger.info(f"ğŸ” [FinanceChart] Generated {len(traces)} traces")

        # 5. æ™ºèƒ½å¸ƒå±€é…ç½®
        series_count = len(traces)
        x_data_len = len(traces[0]["x"]) if traces and traces[0].get("x") else 0

        layout = {
            "title": {"text": title, "font": {"size": 14}},
            "xaxis": {
                "title": {"text": _get_display_name(x_col) if x_col else ""},
                "tickangle": -45 if x_data_len > 6 else (-30 if x_data_len > 4 else 0),
                "tickfont": {"size": 10},
            },
            "yaxis": {
                "title": {"text": "é‡‘é¢ï¼ˆä¸‡å…ƒï¼‰"},
                "tickfont": {"size": 10},
            },
            "barmode": "group",
            "showlegend": series_count > 1,
            "hovermode": "x unified",
        }

        # å›¾ä¾‹ç­–ç•¥ï¼š>3 ç³»åˆ—æ—¶ç«–å‘æ”¾å³ä¾§ï¼Œå¦åˆ™æ°´å¹³æ”¾ä¸‹æ–¹
        if series_count > 3:
            layout["legend"] = {
                "orientation": "v",
                "x": 1.02,
                "y": 1,
                "xanchor": "left",
                "font": {"size": 10},
            }
            layout["margin"] = {"l": 50, "r": 120, "t": 40, "b": 70}
        else:
            layout["legend"] = {
                "orientation": "h",
                "y": -0.2,
                "x": 0.5,
                "xanchor": "center",
                "font": {"size": 10},
            }
            layout["margin"] = {"l": 50, "r": 20, "t": 40, "b": 80}

        return {"data": traces, "layout": layout}

    def _build_pie_config(self, rows, headers, val_col, colors, title):
        """æ„å»ºé¥¼å›¾é…ç½®ã€‚"""
        # ç¡®å®šæ ‡ç­¾åˆ—
        label_col = None
        for col in ["company_name", "type_name", "company_no"]:
            if col in headers:
                label_col = col
                break
        if not label_col:
            label_col = headers[0] if headers else None

        labels = []
        values = []
        for row in rows:
            try:
                value = float(row.get(val_col, 0) or 0)
                label = row.get(label_col, "")
                if label_col == "company_no":
                    label = _get_company_name(str(label))
                labels.append(str(label) if label else "æœªçŸ¥")
                values.append(value)
            except (ValueError, TypeError):
                pass

        return {
            "data": [{
                "type": "pie",
                "labels": labels,
                "values": values,
                "hole": 0.4,
                "textinfo": "label+percent",
                "hovertemplate": "%{label}<br>%{value:,.2f}ä¸‡å…ƒ<br>%{percent}<extra></extra>",
                "marker": {"colors": colors[:len(labels)]},
            }],
            "layout": {
                "title": {"text": title, "font": {"size": 14}},
                "showlegend": True,
                "legend": {"orientation": "v", "x": 1.02, "y": 1, "font": {"size": 10}},
                "margin": {"l": 20, "r": 100, "t": 40, "b": 20},
            },
        }

    def _build_grouped_traces(self, rows, group_col, x_col, val_col, chart_type, colors):
        """æŒ‰åˆ†ç»„åˆ—æ„å»ºå¤šç³»åˆ— tracesï¼ˆå¤šå…¬å¸/å¤šæŒ‡æ ‡ï¼‰ã€‚"""
        logger.info(f"ğŸ” [FinanceChart] _build_grouped_traces: group_col={group_col}, x_col={x_col}, val_col={val_col}, row_count={len(rows)}")
        if rows:
            logger.info(f"ğŸ” [FinanceChart] First row type: {type(rows[0])}, first row: {rows[0]}")
        # è·å–æ‰€æœ‰åˆ†ç»„
        groups = sorted(set(str(row.get(group_col, "")) for row in rows if row.get(group_col)))
        logger.info(f"ğŸ” [FinanceChart] Found {len(groups)} groups: {groups}")

        traces = []
        for i, group in enumerate(groups):
            logger.info(f"ğŸ” [FinanceChart] Processing group {i}: '{group}'")
            # ç­›é€‰è¯¥åˆ†ç»„çš„æ•°æ®
            group_rows = [r for r in rows if str(r.get(group_col, "")) == group]
            logger.info(f"ğŸ” [FinanceChart] Group '{group}' has {len(group_rows)} rows")
            # æŒ‰Xè½´æ’åº
            group_rows.sort(key=lambda r: str(r.get(x_col, "")))

            x_data = []
            y_data = []
            for row in group_rows:
                # Xè½´æ ¼å¼åŒ–
                x_val = row.get(x_col, "")
                if x_col == "keep_date" and x_val:
                    x_val = self._format_date(x_val)
                else:
                    x_val = str(x_val) if x_val else ""
                x_data.append(x_val)

                # Yè½´æ•°å€¼
                try:
                    y_val = float(row.get(val_col, 0) or 0)
                except (ValueError, TypeError):
                    y_val = 0
                y_data.append(y_val)

            trace = {
                "type": "scatter" if chart_type == "line" else "bar",
                "name": group,  # ä½¿ç”¨åˆ†ç»„åä½œä¸ºå›¾ä¾‹
                "x": x_data,
                "y": y_data,
                "marker": {"color": colors[i % len(colors)]},
            }

            if chart_type == "line":
                trace["mode"] = "lines+markers"
                trace["line"] = {"shape": "spline", "smoothing": 1.3}

            logger.info(f"ğŸ” [FinanceChart] Created trace for group '{group}': x_len={len(x_data)}, y_len={len(y_data)}")
            traces.append(trace)

        logger.info(f"ğŸ” [FinanceChart] _build_grouped_traces returning {len(traces)} traces")
        return traces

    def _build_single_traces(self, rows, x_col, value_cols, chart_type, colors):
        """æ„å»ºå•ç³»åˆ—æˆ–æŒ‰æ•°å€¼åˆ—åˆ†ç»„çš„ tracesã€‚"""
        logger.info(f"ğŸ” [FinanceChart] _build_single_traces: x_col={x_col}, value_cols={value_cols}, row_count={len(rows)}")
        # æå– X è½´æ•°æ®
        x_data = []
        for row in rows:
            val = row.get(x_col, "")
            if x_col == "company_no":
                val = _get_company_name(str(val) if val else "")
            elif x_col == "company_name":
                val = str(val) if val else ""
            elif x_col == "keep_date" and val:
                val = self._format_date(val)
            else:
                val = str(val) if val else ""
            x_data.append(val)

        traces = []
        logger.info(f"ğŸ” [FinanceChart] Starting trace generation loop, value_cols count={len(value_cols)}")
        for i, col in enumerate(value_cols):
            display_name = _get_display_name(col)
            y_data = []
            text_data = []
            for row in rows:
                try:
                    val = float(row.get(col, 0) or 0)
                    y_data.append(val)
                    if val >= 10000:
                        text_data.append(f"{val/10000:.2f}äº¿")
                    elif val >= 1:
                        text_data.append(f"{val:,.0f}")
                    else:
                        text_data.append(f"{val:.2f}")
                except (ValueError, TypeError):
                    y_data.append(0)
                    text_data.append("0")

            trace = {
                "type": "scatter" if chart_type == "line" else "bar",
                "name": display_name,
                "x": x_data,
                "y": y_data,
                "marker": {"color": colors[i % len(colors)]},
            }

            if chart_type == "line":
                trace["mode"] = "lines+markers"
                trace["line"] = {"shape": "spline", "smoothing": 1.3}
            else:
                trace["text"] = text_data
                trace["textposition"] = "outside"

            traces.append(trace)

        return traces

    def _format_date(self, val) -> str:
        """å°†æ—¥æœŸæ ¼å¼åŒ–ä¸º 'Xæœˆ' å½¢å¼ã€‚"""
        try:
            if hasattr(val, "month"):
                return f"{val.month}æœˆ"
            else:
                parts = str(val).split("-")
                if len(parts) >= 2:
                    return f"{int(parts[1])}æœˆ"
        except (ValueError, IndexError, AttributeError):
            pass
        return str(val)


class EmployeeChartTool(Tool[EmployeeChartArgs]):
    """åŸºäºæœ€è¿‘çš„å‘˜å·¥ç»Ÿè®¡æŸ¥è¯¢ç”Ÿæˆå›¾è¡¨"""

    @property
    def name(self) -> str:
        return "generate_employee_chart"

    @property
    def description(self) -> str:
        return "åŸºäºæœ€è¿‘çš„å‘˜å·¥ç»Ÿè®¡æŸ¥è¯¢ï¼ˆGROUP BYï¼‰ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨ï¼ˆæŸ±çŠ¶å›¾/é¥¼å›¾ï¼‰"

    def get_args_schema(self):
        return EmployeeChartArgs

    async def execute(self, context: ToolContext, args: EmployeeChartArgs) -> ToolResult:
        # 1. ä»context.metadata["tool_log"]è·å–æœ€è¿‘çš„æŸ¥è¯¢ç»“æœ
        last_tool_result = self._get_last_employee_query_result(context)

        if not last_tool_result:
            return ToolResult(
                success=False,
                error="æœªæ‰¾åˆ°å‘˜å·¥æŸ¥è¯¢ç»“æœï¼Œè¯·å…ˆè°ƒç”¨ query_employees è·å–æ•°æ®ã€‚"
            )

        results = last_tool_result.get("results", [])
        columns = last_tool_result.get("columns", [])
        chart_hint = last_tool_result.get("chart_hint", {})

        if not results or not columns:
            return ToolResult(success=False, error="æŸ¥è¯¢ç»“æœä¸ºç©ºï¼Œæ— æ³•ç”Ÿæˆå›¾è¡¨ã€‚")

        # 2. ç¡®å®šå›¾è¡¨ç±»å‹
        chart_type = args.chart_type or chart_hint.get("recommended_type", "bar")
        title = args.title or "å‘˜å·¥ç»Ÿè®¡å›¾è¡¨"

        # 3. æ„å»ºPlotlyé…ç½®
        chart_config = self._build_plotly_config(
            results,
            columns,
            chart_type,
            title,
            chart_hint
        )

        # 4. è¿”å›å›¾è¡¨metadata
        return ToolResult(
            success=True,
            result_for_llm=f"å·²ç”Ÿæˆ{chart_type}å›¾è¡¨ï¼Œå±•ç¤ºå‘˜å·¥ç»Ÿè®¡æ•°æ®ã€‚",
            metadata={
                "charts": [{
                    "chart_type": chart_type,
                    "config": chart_config,
                    "title": title
                }]
            }
        )

    def _get_last_employee_query_result(self, context: ToolContext) -> Optional[Dict]:
        """ä»tool_logä¸­è·å–æœ€è¿‘çš„å‘˜å·¥æŸ¥è¯¢ç»“æœ"""
        if "tool_log" not in context.metadata:
            return None

        # å€’åºæŸ¥æ‰¾æœ€è¿‘çš„ query_employees è°ƒç”¨
        for log_entry in reversed(context.metadata["tool_log"]):
            if log_entry.get("tool_name") == "query_employees":
                return log_entry.get("metadata", {})

        return None

    def _build_plotly_config(self, results: List[Dict], columns: List[str], chart_type: str,
                            title: str, chart_hint: Dict) -> Dict[str, Any]:
        """æ„å»ºPlotlyå›¾è¡¨é…ç½®ï¼ˆå‚è€ƒFinanceChartToolçš„å®ç°ï¼‰"""

        dimension_cols = chart_hint.get("dimension_cols", [])
        metric_cols = chart_hint.get("metric_cols", [])

        # å›é€€ï¼šè‡ªåŠ¨è¯†åˆ«
        if not dimension_cols or not metric_cols:
            for col in columns:
                col_lower = col.lower()
                if any(name in col_lower for name in ['count', 'sum', 'avg', 'total', 'max', 'min']):
                    metric_cols.append(col)
                else:
                    dimension_cols.append(col)

        # æŸ±çŠ¶å›¾ï¼šç»´åº¦åœ¨Xè½´ï¼ŒæŒ‡æ ‡åœ¨Yè½´
        if chart_type == "bar":
            return self._build_bar_chart(results, dimension_cols[0] if dimension_cols else columns[0],
                                         metric_cols if metric_cols else [columns[-1]], title)

        # é¥¼å›¾ï¼šåªæ˜¾ç¤ºä¸€ä¸ªæŒ‡æ ‡çš„åˆ†å¸ƒ
        elif chart_type == "pie":
            return self._build_pie_chart(results, dimension_cols[0] if dimension_cols else columns[0],
                                         metric_cols[0] if metric_cols else columns[-1], title)

        # é»˜è®¤æŸ±çŠ¶å›¾
        else:
            return self._build_bar_chart(results, dimension_cols[0] if dimension_cols else columns[0],
                                         metric_cols if metric_cols else [columns[-1]], title)

    def _build_bar_chart(self, results: List[Dict], x_col: str, y_cols: List[str], title: str) -> Dict[str, Any]:
        """æ„å»ºæŸ±çŠ¶å›¾é…ç½®"""
        colors = [
            "#3b82f6", "#10b981", "#f59e0b", "#ef4444", "#8b5cf6", "#ec4899",
            "#06b6d4", "#84cc16", "#f97316", "#6366f1", "#14b8a6", "#a855f7",
        ]

        traces = []

        for i, y_col in enumerate(y_cols):
            # è·å–åˆ—çš„ä¸­æ–‡å
            y_label = EMPLOYEE_COLUMN_LABELS.get(y_col, y_col)

            traces.append({
                "type": "bar",
                "name": y_label,
                "x": [str(row.get(x_col, "")) for row in results],
                "y": [float(row.get(y_col, 0) or 0) for row in results],
                "marker": {"color": colors[i % len(colors)]},
            })

        # è·å–Xè½´åˆ—çš„ä¸­æ–‡å
        x_label = EMPLOYEE_COLUMN_LABELS.get(x_col, x_col)

        return {
            "data": traces,
            "layout": {
                "title": {"text": title, "font": {"size": 14}},
                "xaxis": {
                    "title": {"text": x_label},
                    "tickangle": -45 if len(results) > 6 else (-30 if len(results) > 4 else 0),
                    "tickfont": {"size": 10},
                },
                "yaxis": {"title": {"text": "æ•°é‡"}, "tickfont": {"size": 10}},
                "barmode": "group" if len(y_cols) > 1 else "relative",
                "showlegend": len(y_cols) > 1,
                "hovermode": "x unified",
                "margin": {"l": 50, "r": 20, "t": 40, "b": 100},
            }
        }

    def _build_pie_chart(self, results: List[Dict], label_col: str, value_col: str, title: str) -> Dict[str, Any]:
        """æ„å»ºé¥¼å›¾é…ç½®"""
        colors = [
            "#3b82f6", "#10b981", "#f59e0b", "#ef4444", "#8b5cf6", "#ec4899",
            "#06b6d4", "#84cc16", "#f97316", "#6366f1", "#14b8a6", "#a855f7",
        ]

        labels = [str(row.get(label_col, "")) for row in results]
        values = [float(row.get(value_col, 0) or 0) for row in results]

        return {
            "data": [{
                "type": "pie",
                "labels": labels,
                "values": values,
                "hole": 0.4,
                "textinfo": "label+percent",
                "hovertemplate": "%{label}<br>%{value}<extra></extra>",
                "marker": {"colors": colors[:len(labels)]},
            }],
            "layout": {
                "title": {"text": title, "font": {"size": 14}},
                "showlegend": True,
                "legend": {
                    "orientation": "v",
                    "x": 1.02,
                    "y": 1,
                    "xanchor": "left",
                    "font": {"size": 10}
                },
                "margin": {"l": 20, "r": 120, "t": 40, "b": 20},
            }
        }


class EmployeeQueryTool(Tool[EmployeeQueryArgs]):
    """å‘˜å·¥æ•°æ®æŸ¥è¯¢å·¥å…·ï¼Œå¸¦æƒé™æ§åˆ¶ã€‚

    æ ¹æ®ç”¨æˆ·è§’è‰²è‡ªåŠ¨é€‰æ‹©åˆé€‚çš„è§†å›¾ï¼š
    - admin: å¯è§å…¨éƒ¨å­—æ®µï¼ˆå«èº«ä»½è¯å·ã€ç”µè¯ç­‰æ•æ„Ÿä¿¡æ¯ï¼‰
    - viewer: ä»…å¯è§åŸºç¡€å­—æ®µï¼ˆä¸å«èº«ä»½è¯ã€ç”µè¯ï¼‰
    - finance: æ— æƒè®¿é—®å‘˜å·¥æ•°æ®
    """

    def __init__(self, user_role: str):
        # ğŸ” è¯Šæ–­æ—¥å¿—ï¼šå·¥å…·åˆå§‹åŒ–
        logger.info(f"ğŸ” [EmployeeQueryTool] Initializing with user_role='{user_role}'")

        self.user_role = user_role
        self.sql_runner = EmployeeSqlRunner(user_role)

        # ğŸ” è¯Šæ–­æ—¥å¿—ï¼šSqlRunner çŠ¶æ€
        logger.info(f"âœ“ [EmployeeQueryTool] SqlRunner initialized:")
        logger.info(f"  - target_view: {self.sql_runner.target_view}")
        logger.info(f"  - can_access: {self.sql_runner.can_access}")

    @property
    def name(self) -> str:
        return "query_employees"

    @property
    def description(self) -> str:
        if not self.sql_runner.can_access:
            return "å‘˜å·¥æ•°æ®æŸ¥è¯¢ï¼ˆå½“å‰è§’è‰²æ— æƒè®¿é—®ï¼‰"

        schema_desc = self.sql_runner.get_schema_description()

        # æ ¹æ®è§’è‰²ç”Ÿæˆä¸åŒçš„è¡¨åæŒ‡å¯¼
        if self.user_role in {Roles.ADMIN}:
            table_name = "employees"
            table_note = "ä½¿ç”¨å®Œæ•´è¡¨ employeesï¼Œå¯æŸ¥è¯¢åŒ…æ‹¬ phoneï¼ˆç”µè¯ï¼‰ã€id_numberï¼ˆèº«ä»½è¯å·ï¼‰åœ¨å†…çš„å…¨éƒ¨å­—æ®µ"
        else:
            table_name = "employees_basic"
            table_note = "ä½¿ç”¨åŸºç¡€è§†å›¾ employees_basicï¼Œä»…å¯æŸ¥è¯¢åŸºç¡€å­—æ®µï¼ˆä¸å«æ•æ„Ÿä¿¡æ¯ï¼‰"

        return f"""æŸ¥è¯¢å‘˜å·¥æ•°æ®ï¼ˆå§“åã€éƒ¨é—¨ã€èŒåŠ¡ã€å­¦å†ç­‰ï¼‰ã€‚

{schema_desc}

é‡è¦è¯´æ˜:
- è¡¨å: {table_name}
- æƒé™: {table_note}
- æŸ¥è¯¢å…¬å¸å‘˜å·¥æ—¶ï¼ŒåŠ¡å¿…ä½¿ç”¨ ILIKE æ¨¡ç³ŠåŒ¹é…: WHERE company_name ILIKE '%å…³é”®è¯%'
- ç¤ºä¾‹: SELECT name, department, position FROM {table_name} WHERE company_name ILIKE '%è”ç¯%' LIMIT 20
"""

    def get_args_schema(self):
        return EmployeeQueryArgs

    async def execute(self, context: ToolContext, args: EmployeeQueryArgs) -> ToolResult:
        # ğŸ” è¯Šæ–­æ—¥å¿—ï¼šå·¥å…·è°ƒç”¨
        logger.info(f"[EmployeeQueryTool] Called with SQL: {args.sql}")
        logger.info(f"[EmployeeQueryTool] User role: {self.user_role}, Can access: {self.sql_runner.can_access}")

        if not self.sql_runner.can_access:
            logger.warning(f"[EmployeeQueryTool] Access denied for role {self.user_role}")
            return ToolResult(
                success=False,
                error=f"è§’è‰² {self.user_role} æ— æƒè®¿é—®å‘˜å·¥æ•°æ®"
            )

        try:
            from vanna.capabilities.sql_runner.models import RunSqlToolArgs
            sql_args = RunSqlToolArgs(sql=args.sql)
            df = await self.sql_runner.run_sql(sql_args, context)

            # ğŸ” è¯Šæ–­æ—¥å¿—ï¼šSQL æ‰§è¡Œç»“æœ
            logger.info(f"[EmployeeQueryTool] SQL execution returned {len(df)} rows")

            # æ„å»ºç»“æœ
            if df.empty:
                logger.warning("[EmployeeQueryTool] Empty result, returning empty response")
                return ToolResult(
                    success=True,
                    result_for_llm="æŸ¥è¯¢ç»“æœä¸ºç©ºï¼Œæ²¡æœ‰æ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„å‘˜å·¥è®°å½•ã€‚",
                    metadata={}  # ä¸è¿”å› results/columnsï¼Œé¿å…åˆ›å»ºç©ºè¡¨æ ¼ç»„ä»¶
                )

            # ğŸ”§ æ£€æµ‹èšåˆæŸ¥è¯¢ç±»å‹
            is_aggregate, agg_type = self._detect_aggregate_type(args.sql, df)

            # åœºæ™¯1: å•å€¼èšåˆï¼ˆCOUNT(*) â†’ 1è¡Œ1åˆ—ï¼‰
            if is_aggregate and agg_type == "single_value":
                agg_col = df.columns[0]
                agg_value = df.iloc[0][agg_col]

                logger.info(f"[EmployeeQueryTool] Detected single value aggregate: {agg_col}={agg_value}")

                # ğŸ”§ å°†numpyç±»å‹è½¬æ¢ä¸ºPythonåŸç”Ÿç±»å‹ï¼ˆè§£å†³JSONåºåˆ—åŒ–é—®é¢˜ï¼‰
                if hasattr(agg_value, 'item'):
                    python_value = agg_value.item()
                else:
                    python_value = agg_value

                return ToolResult(
                    success=True,
                    result_for_llm=f"ç»Ÿè®¡ç»“æœï¼š{self._translate_column(agg_col)}ä¸º {python_value}ã€‚",
                    metadata={
                        "aggregate_result": {
                            "label": self._translate_column(agg_col),
                            "value": python_value,
                            "raw_column": agg_col,
                        },
                        "is_aggregate": True,
                        "aggregate_type": "single_value",
                    }
                )

            # åœºæ™¯2: GROUP BYç»Ÿè®¡ï¼ˆå¤šè¡Œï¼Œå«èšåˆåˆ—ï¼‰
            elif is_aggregate and agg_type == "grouped_stats":
                logger.info(f"[EmployeeQueryTool] Detected grouped statistics with {len(df)} rows")

                # è¯†åˆ«ç»´åº¦åˆ—å’ŒæŒ‡æ ‡åˆ—
                dimension_cols, metric_cols = self._identify_columns(df, args.sql)

                logger.info(f"[EmployeeQueryTool] Dimension cols: {dimension_cols}, Metric cols: {metric_cols}")

                # è¿‡æ»¤éšè—å­—æ®µ
                hidden_columns = {"id", "raw_data", "created_at", "updated_at"}
                columns = [col for col in df.columns if col not in hidden_columns]
                results = [
                    {k: v for k, v in row.items() if k not in hidden_columns}
                    for row in df.to_dict(orient="records")
                ]

                # ç”Ÿæˆä¸­æ–‡åˆ—åæ˜ å°„
                column_labels = {col: EMPLOYEE_COLUMN_LABELS.get(col, col) for col in columns}

                return ToolResult(
                    success=True,
                    result_for_llm=f"æŸ¥è¯¢åˆ° {len(results)} ä¸ªåˆ†ç»„çš„ç»Ÿè®¡æ•°æ®ï¼Œå·²ç”Ÿæˆæ•°æ®è¡¨ã€‚å»ºè®®è°ƒç”¨ generate_employee_chart å·¥å…·å¯è§†åŒ–å±•ç¤ºã€‚",
                    metadata={
                        "results": results,
                        "columns": columns,
                        "column_labels": column_labels,
                        "is_aggregate": True,
                        "aggregate_type": "grouped_stats",
                        "chart_hint": {
                            "recommended_type": self._recommend_chart_type(df, dimension_cols, metric_cols),
                            "dimension_cols": dimension_cols,
                            "metric_cols": metric_cols,
                        },
                    }
                )

            # æ˜ç»†æŸ¥è¯¢ï¼šæ­£å¸¸è¿”å›
            # è½¬æ¢ä¸ºåˆ—è¡¨æ ¼å¼ï¼Œè¿‡æ»¤æ‰å†…éƒ¨å­—æ®µ
            hidden_columns = {"id", "raw_data", "created_at", "updated_at"}
            columns = [col for col in df.columns if col not in hidden_columns]
            results = [
                {k: v for k, v in row.items() if k not in hidden_columns}
                for row in df.to_dict(orient="records")
            ]

            # ç”Ÿæˆä¸­æ–‡åˆ—åæ˜ å°„
            column_labels = {col: EMPLOYEE_COLUMN_LABELS.get(col, col) for col in columns}

            # ç”Ÿæˆæ•°æ®æ‘˜è¦ä¾› LLM å¼•ç”¨ï¼ˆé¿å… LLM ç¼–é€ æ•°æ®ï¼‰
            summary_lines = []
            for row in results[:10]:  # æœ€å¤šæ˜¾ç¤ºå‰10æ¡
                name = row.get("name", "")
                dept = row.get("department", "")
                pos = row.get("position", "")
                edu = row.get("highest_education", "")
                summary_lines.append(f"- {name}ï¼Œ{dept}ï¼Œ{pos}ï¼Œ{edu}")

            data_summary = "\n".join(summary_lines)
            if len(results) > 10:
                data_summary += f"\n... å…± {len(results)} æ¡è®°å½•"

            # ğŸ” è¯Šæ–­æ—¥å¿—ï¼šè¿”å›ç»“æœ
            logger.info(f"[EmployeeQueryTool] Returning {len(results)} records with {len(columns)} columns")
            logger.info(f"[EmployeeQueryTool] Columns: {columns}")

            return ToolResult(
                success=True,
                result_for_llm=(
                    f"æŸ¥è¯¢åˆ° {len(results)} æ¡å‘˜å·¥è®°å½•ï¼š\n{data_summary}\n\n"
                    "ä»¥ä¸Šæ•°æ®å·²åœ¨è¡¨æ ¼ç»„ä»¶ä¸­å®Œæ•´å±•ç¤ºã€‚è¯·ç”¨è‡ªç„¶è¯­è¨€æ€»ç»“å›ç­”ï¼Œç¦æ­¢ç”Ÿæˆ markdown è¡¨æ ¼ã€‚"
                ),
                metadata={
                    "results": results,
                    "columns": columns,
                    "column_labels": column_labels,
                    "total": len(results),
                    "title": "å‘˜å·¥æŸ¥è¯¢ç»“æœ",
                    "is_aggregate": False,
                }
            )

        except PermissionError as e:
            return ToolResult(success=False, error=str(e))
        except ValueError as e:
            return ToolResult(success=False, error=str(e))
        except Exception as e:
            return ToolResult(success=False, error=f"æŸ¥è¯¢å‡ºé”™: {str(e)}")

    def _detect_aggregate_type(self, sql: str, df: pd.DataFrame) -> Tuple[bool, str]:
        """æ£€æµ‹èšåˆæŸ¥è¯¢ç±»å‹ã€‚

        è¿”å›:
            (is_aggregate, aggregate_type)
            - is_aggregate: bool - æ˜¯å¦æ˜¯èšåˆæŸ¥è¯¢
            - aggregate_type: str - "single_value"ï¼ˆå•å€¼èšåˆï¼‰, "grouped_stats"ï¼ˆåˆ†ç»„ç»Ÿè®¡ï¼‰, "none"ï¼ˆæ˜ç»†æŸ¥è¯¢ï¼‰
        """
        sql_lower = sql.lower()

        # æ£€æµ‹èšåˆå‡½æ•°
        has_agg_func = any(f in sql_lower for f in ['count(', 'sum(', 'avg(', 'max(', 'min('])

        # æ£€æµ‹åˆ—åä¸­çš„èšåˆæ ‡è¯†
        agg_cols = {'count', 'sum', 'avg', 'max', 'min', 'total', 'average'}
        has_agg_col = any(col.lower() in agg_cols for col in df.columns)

        # æ£€æµ‹ GROUP BY å…³é”®å­—
        has_group_by = 'group by' in sql_lower

        # åœºæ™¯1: å•è¡Œç»“æœ + èšåˆå‡½æ•°/åˆ—å â†’ å•å€¼èšåˆï¼ˆå¦‚ COUNT(*) â†’ 1è¡Œï¼‰
        if len(df) == 1 and (has_agg_func or has_agg_col):
            return True, "single_value"

        # åœºæ™¯2: å¤šè¡Œç»“æœ + GROUP BY + èšåˆå‡½æ•°/åˆ—å â†’ ç»Ÿè®¡åˆ†ç»„ï¼ˆå¦‚ GROUP BY company_nameï¼‰
        if len(df) > 1 and has_group_by and (has_agg_func or has_agg_col):
            return True, "grouped_stats"

        return False, "none"

    def _is_aggregate_query(self, sql: str, df: pd.DataFrame) -> bool:
        """æ£€æµ‹æ˜¯å¦æ˜¯èšåˆæŸ¥è¯¢ï¼ˆå…¼å®¹æ—§æ¥å£ï¼‰ã€‚"""
        is_agg, _ = self._detect_aggregate_type(sql, df)
        return is_agg

    def _translate_column(self, col: str) -> str:
        """ç¿»è¯‘èšåˆåˆ—åä¸ºä¸­æ–‡ã€‚"""
        translations = {
            'count': 'æ•°é‡',
            'sum': 'æ€»å’Œ',
            'avg': 'å¹³å‡å€¼',
            'average': 'å¹³å‡å€¼',
            'max': 'æœ€å¤§å€¼',
            'min': 'æœ€å°å€¼',
            'total': 'æ€»è®¡',
        }
        return translations.get(col.lower(), col)

    def _identify_columns(self, df: pd.DataFrame, sql: str) -> Tuple[List[str], List[str]]:
        """è¯†åˆ«ç»´åº¦åˆ—ï¼ˆåˆ†ç»„é”®ï¼‰å’ŒæŒ‡æ ‡åˆ—ï¼ˆèšåˆå€¼ï¼‰ã€‚

        è¿”å›:
            (dimension_cols, metric_cols)
        """
        dimension_cols = []
        metric_cols = []

        for col in df.columns:
            col_lower = col.lower()
            # æŒ‡æ ‡åˆ—ç‰¹å¾ï¼šèšåˆå‡½æ•°å æˆ– æ•°å€¼ç±»å‹
            if any(name in col_lower for name in ['count', 'sum', 'avg', 'total', 'max', 'min', 'bachelor_count']):
                metric_cols.append(col)
            # ç»´åº¦åˆ—ï¼šéèšåˆçš„åˆ—
            else:
                dimension_cols.append(col)

        return dimension_cols, metric_cols

    def _recommend_chart_type(self, df: pd.DataFrame, dimension_cols: List[str], metric_cols: List[str]) -> str:
        """æ ¹æ®æ•°æ®ç‰¹å¾æ¨èå›¾è¡¨ç±»å‹ã€‚"""
        # å•ç»´åº¦ + å•æŒ‡æ ‡ â†’ é¥¼å›¾æˆ–æŸ±çŠ¶å›¾
        if len(dimension_cols) == 1 and len(metric_cols) == 1:
            # å¦‚æœç»´åº¦æ˜¯å…¬å¸/éƒ¨é—¨ï¼Œæ¨èæŸ±çŠ¶å›¾
            dim_col = dimension_cols[0].lower()
            if 'company' in dim_col or 'department' in dim_col:
                return "bar"
            # å¦‚æœæ˜¯åˆ†ç±»ï¼ˆå¦‚å­¦å†ï¼‰ï¼Œæ¨èé¥¼å›¾
            return "pie"

        # å•ç»´åº¦ + å¤šæŒ‡æ ‡ â†’ åˆ†ç»„æŸ±çŠ¶å›¾
        elif len(dimension_cols) == 1 and len(metric_cols) > 1:
            return "bar"

        # é»˜è®¤æŸ±çŠ¶å›¾
        return "bar"


def build_tools(mode: str, user_role: str = "viewer") -> List[Tool]:
    """Return tools for the given mode and user role.

    Args:
        mode: æ¨¡å¼ - "rag", "sql", "hybrid"
        user_role: ç”¨æˆ·è§’è‰² - "admin", "finance", "viewer"

    Returns:
        å·¥å…·åˆ—è¡¨

    æƒé™çŸ©é˜µï¼š
    - admin: è´¢åŠ¡ + å‘˜å·¥å…¨å­—æ®µ + æ”¿ç­–ï¼ˆhybridæ¨¡å¼ï¼‰
    - finance: åªæœ‰è´¢åŠ¡ï¼ˆsqlæ¨¡å¼ï¼‰
    - viewer: æ”¿ç­– + å‘˜å·¥åŸºç¡€ï¼ˆragæ¨¡å¼ã€PCå¯¹è¯ï¼‰
    """
    tools: List[Tool] = []

    # è´¢åŠ¡æŸ¥è¯¢å·¥å…·ï¼ˆä»… admin å’Œ finance è§’è‰²å¯ç”¨ï¼‰
    if user_role in {Roles.ADMIN, Roles.FINANCE}:
        sql_runner = FinanceSqlRunner()
        sql_tool = RunSqlTool(
            sql_runner=sql_runner,
            file_system=LocalFileSystem(working_directory="vanna_outputs"),
            custom_tool_name="query_finance_sql",
            custom_tool_description="åªè¯»æŸ¥è¯¢ finance_recordsï¼Œå›ç­”è¥ä¸šæ”¶å…¥/åˆ©æ¶¦ç­‰è´¢åŠ¡é—®é¢˜ã€‚",
        )
        chart_tool = FinanceChartTool()
    else:
        sql_tool = None
        chart_tool = None

    # æ”¿ç­–æ£€ç´¢å·¥å…·ï¼ˆadmin å’Œ viewer å¯ç”¨ï¼Œfinance ä¸å¯ç”¨ï¼‰
    search_tool = SearchArticlesTool() if user_role != Roles.FINANCE else None

    # å‘˜å·¥æŸ¥è¯¢å·¥å…·ï¼ˆadmin å’Œ viewer å¯ç”¨ï¼Œfinance ä¸å¯ç”¨ï¼‰
    employee_tool = EmployeeQueryTool(user_role)
    employee_chart_tool = EmployeeChartTool()

    # æ ¹æ®æ¨¡å¼ç»„åˆå·¥å…·
    if mode == "sql":
        # sql æ¨¡å¼ï¼šåªæœ‰è´¢åŠ¡å·¥å…·ï¼ˆfinance è§’è‰²ä¸“ç”¨ï¼‰
        if sql_tool:
            tools.extend([sql_tool, chart_tool])
    elif mode == "rag":
        # rag æ¨¡å¼ï¼šæ”¿ç­– + å‘˜å·¥åŸºç¡€ï¼ˆviewer è§’è‰²ï¼‰
        if search_tool:
            tools.append(search_tool)
        if employee_tool.sql_runner.can_access:
            tools.append(employee_tool)
            tools.append(employee_chart_tool)
    else:  # hybrid æ¨¡å¼ï¼šå…¨éƒ¨å·¥å…·ï¼ˆadmin è§’è‰²ï¼‰
        if sql_tool:
            tools.extend([sql_tool, chart_tool])
        if search_tool:
            tools.append(search_tool)
        if employee_tool.sql_runner.can_access:
            tools.append(employee_tool)
            tools.append(employee_chart_tool)

    return tools


def register_tools(registry: ToolRegistry, mode: str, user_role: str = "viewer") -> None:
    """æ³¨å†Œå·¥å…·åˆ° registryã€‚

    Args:
        registry: Vanna ToolRegistry
        mode: æ¨¡å¼ - "rag", "sql", "hybrid"
        user_role: ç”¨æˆ·è§’è‰²
    """
    for tool in build_tools(mode, user_role):
        registry.register_local_tool(tool, access_groups=[])


__all__ = [
    "build_tools",
    "SearchArticlesTool",
    "FinanceChartTool",
    "EmployeeChartTool",
    "EmployeeQueryTool",
    "register_tools",
]
